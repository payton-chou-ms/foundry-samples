# ------------------------------------
# Copyright (c) Microsoft Corporation.
# Licensed under the MIT License.
# ------------------------------------

"""
èªªæ˜:
    æ­¤æª”æ¡ˆå¯¦ç¾äº†åŸºæ–¼ Semantic Kernel çš„å¤šä»£ç†ç¨‹å¼å”ä½œç§»äº¤ï¼ˆhandoffï¼‰æ©Ÿåˆ¶ã€‚
    ä½¿ç”¨ Semantic Kernel çš„ ChatCompletionAgent ä¾†æ›¿ä»£åŸæœ¬çš„ Azure AI Projects agentsã€‚
    å…è¨±ä¸åŒå°ˆæ¥­çš„ä»£ç†ç¨‹å¼ä¹‹é–“å”ä½œå®Œæˆè¤‡é›œä»»å‹™ã€‚
    
ä½¿ç”¨æ–¹å¼:
    python step4_handoff-semantic-kernel.py

å‰ç½®æ¢ä»¶:
    pip install semantic-kernel azure-identity python-dotenv
    
    è¨­å®šç’°å¢ƒè®Šæ•¸ï¼š
    - AZURE_OPENAI_ENDPOINT
    - AZURE_OPENAI_API_KEY (æˆ–ä½¿ç”¨ DefaultAzureCredential)
    - MODEL_DEPLOYMENT_NAME
"""

import os
import json
import asyncio
import logging
from typing import Dict, Any, Optional, List, Callable, Union
from datetime import datetime
from dataclasses import dataclass
from enum import Enum
from dotenv import load_dotenv

# Semantic Kernel imports
try:
    from semantic_kernel import Kernel
    from semantic_kernel.agents import ChatCompletionAgent
    from semantic_kernel.agents.runtime import InProcessRuntime
    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion
    from semantic_kernel.contents import ChatMessageContent, ChatHistory
    from semantic_kernel.functions import kernel_function, KernelArguments
    from semantic_kernel.planners import FunctionCallingStepwisePlanner
    SEMANTIC_KERNEL_AVAILABLE = True
except ImportError:
    print("Warning: Semantic Kernel packages not available. Running in mock mode.")
    SEMANTIC_KERNEL_AVAILABLE = False
    # Mock classes for testing
    class Kernel: pass
    class ChatCompletionAgent: pass
    class InProcessRuntime: pass
    class AzureChatCompletion: pass
    class ChatMessageContent: pass
    class ChatHistory: pass
    class KernelArguments: pass

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class HandoffType(Enum):
    """ç§»äº¤é¡å‹å®šç¾©"""
    FORWARD = "forward"  # è½‰ç™¼çµ¦ç‰¹å®šä»£ç†
    ESCALATE = "escalate"  # å‡ç´šçµ¦æ›´å°ˆæ¥­çš„ä»£ç†
    COLLABORATE = "collaborate"  # å¤šä»£ç†å”ä½œ
    COMPLETE = "complete"  # ä»»å‹™å®Œæˆ

@dataclass
class HandoffRequest:
    """ç§»äº¤è«‹æ±‚çš„æ•¸æ“šçµæ§‹"""
    from_agent: str
    to_agent: Optional[str]
    handoff_type: HandoffType
    task_description: str
    context: Dict[str, Any]
    timestamp: datetime
    priority: int = 5  # 1-10, 10ç‚ºæœ€é«˜å„ªå…ˆç´š

class SemanticKernelBaseAgent:
    """åŸºæ–¼ Semantic Kernel çš„åŸºç¤ä»£ç†ç¨‹å¼é¡åˆ¥"""
    
    def __init__(self, name: str, description: str, instructions: str, plugins: List[Any] = None):
        self.name = name
        self.description = description
        self.instructions = instructions
        self.plugins = plugins or []
        self.agent = None
        self.kernel = None
        self.chat_history = None
        
    async def initialize(self, kernel: Kernel = None) -> None:
        """åˆå§‹åŒ–ä»£ç†ç¨‹å¼"""
        if not SEMANTIC_KERNEL_AVAILABLE:
            logger.warning(f"Semantic Kernel not available, agent '{self.name}' running in mock mode")
            return
            
        # Create or use provided kernel
        if kernel is None:
            self.kernel = Kernel()
            
            # Add Azure OpenAI service
            azure_openai = AzureChatCompletion(
                deployment_name=os.environ.get("MODEL_DEPLOYMENT_NAME", "gpt-4o"),
                endpoint=os.environ.get("AZURE_OPENAI_ENDPOINT"),
                api_key=os.environ.get("AZURE_OPENAI_API_KEY")
            )
            self.kernel.add_service(azure_openai)
        else:
            self.kernel = kernel
        
        # Add plugins to kernel
        for plugin in self.plugins:
            self.kernel.add_plugin(plugin, plugin.__class__.__name__)
        
        # Create chat completion agent
        self.agent = ChatCompletionAgent(
            service_id="chat-gpt",
            kernel=self.kernel,
            name=self.name,
            instructions=self.instructions,
            description=self.description
        )
        
        # Initialize chat history
        self.chat_history = ChatHistory()
        
        logger.info(f"Semantic Kernel Agent '{self.name}' initialized")
        
    async def process_task(self, task: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """è™•ç†ä»»å‹™ä¸¦è¿”å›çµæœ"""
        if not SEMANTIC_KERNEL_AVAILABLE:
            return {
                "success": True,
                "response": f"Mock response from {self.name}: Task '{task[:50]}...' processed successfully",
                "agent": self.name,
                "conversation_id": "mock_conversation_id"
            }
            
        if not self.agent:
            raise RuntimeError(f"Agent '{self.name}' not initialized")
        
        try:
            # Add context to the task if provided
            full_task = task
            if context:
                context_str = json.dumps(context, indent=2, ensure_ascii=False)
                full_task = f"{task}\n\nç›¸é—œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š\n{context_str}"
            
            # Add user message to chat history
            self.chat_history.add_user_message(full_task)
            
            # Get response from agent
            async for response in self.agent.invoke(self.chat_history):
                if response.role.label == "assistant":
                    # Add assistant response to history
                    self.chat_history.add_message(response)
                    
                    return {
                        "success": True,
                        "response": response.content,
                        "agent": self.name,
                        "conversation_id": f"sk_{self.name}_{len(self.chat_history)}"
                    }
            
            return {
                "success": False,
                "error": "No response received from agent",
                "agent": self.name
            }
            
        except Exception as e:
            logger.error(f"Error processing task in agent '{self.name}': {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "agent": self.name
            }
    
    def should_handoff(self, task: str, context: Dict[str, Any] = None) -> Optional[HandoffRequest]:
        """åˆ¤æ–·æ˜¯å¦éœ€è¦ç§»äº¤çµ¦å…¶ä»–ä»£ç†ç¨‹å¼"""
        # åŸºç¤é¡åˆ¥é»˜èªä¸ç§»äº¤ï¼Œå­é¡åˆ¥å¯ä»¥é‡å¯«æ­¤æ–¹æ³•
        return None
    
    async def cleanup(self):
        """æ¸…ç†è³‡æº"""
        logger.info(f"Semantic Kernel Agent '{self.name}' cleanup completed")

class SemanticKernelOrchestrator:
    """åŸºæ–¼ Semantic Kernel çš„ç§»äº¤å”èª¿å™¨ï¼Œç®¡ç†å¤šä»£ç†ç¨‹å¼ä¹‹é–“çš„å”ä½œ"""
    
    def __init__(self):
        self.agents: Dict[str, SemanticKernelBaseAgent] = {}
        self.handoff_history: List[HandoffRequest] = []
        self.kernel = None
        self.runtime = None
        
    async def initialize(self):
        """åˆå§‹åŒ–å”èª¿å™¨å’Œé‹è¡Œæ™‚"""
        if not SEMANTIC_KERNEL_AVAILABLE:
            logger.warning("Semantic Kernel not available, orchestrator running in mock mode")
            return
            
        # Create shared kernel
        self.kernel = Kernel()
        
        # Add Azure OpenAI service
        azure_openai = AzureChatCompletion(
            deployment_name=os.environ.get("MODEL_DEPLOYMENT_NAME", "gpt-4o"),
            endpoint=os.environ.get("AZURE_OPENAI_ENDPOINT"),
            api_key=os.environ.get("AZURE_OPENAI_API_KEY")
        )
        self.kernel.add_service(azure_openai)
        
        # Create and start runtime
        self.runtime = InProcessRuntime()
        self.runtime.start()
        
        logger.info("Semantic Kernel Orchestrator initialized")
    
    def register_agent(self, agent: SemanticKernelBaseAgent):
        """è¨»å†Šä»£ç†ç¨‹å¼"""
        self.agents[agent.name] = agent
        logger.info(f"Registered Semantic Kernel agent: {agent.name}")
    
    async def initialize_all_agents(self):
        """åˆå§‹åŒ–æ‰€æœ‰ä»£ç†ç¨‹å¼"""
        for agent in self.agents.values():
            await agent.initialize(self.kernel)
    
    async def execute_task(self, task: str, initial_agent: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """åŸ·è¡Œä»»å‹™ï¼Œæ”¯æ´ä»£ç†ç¨‹å¼é–“ç§»äº¤"""
        if initial_agent not in self.agents:
            return {
                "success": False,
                "error": f"Agent '{initial_agent}' not found"
            }
        
        current_agent = self.agents[initial_agent]
        execution_history = []
        max_handoffs = 10  # é˜²æ­¢ç„¡é™å¾ªç’°
        handoff_count = 0
        
        current_task = task
        current_context = context or {}
        
        while handoff_count < max_handoffs:
            logger.info(f"Processing task with Semantic Kernel agent: {current_agent.name}")
            
            # Process task with current agent
            result = await current_agent.process_task(current_task, current_context)
            execution_history.append({
                "agent": current_agent.name,
                "task": current_task,
                "result": result,
                "timestamp": datetime.now().isoformat()
            })
            
            if not result.get("success"):
                break
            
            # Check if handoff is needed
            handoff_request = current_agent.should_handoff(current_task, current_context)
            if not handoff_request:
                # Task completed, no handoff needed
                break
            
            # Record handoff
            self.handoff_history.append(handoff_request)
            handoff_count += 1
            
            if handoff_request.handoff_type == HandoffType.COMPLETE:
                break
            elif handoff_request.handoff_type in [HandoffType.FORWARD, HandoffType.ESCALATE]:
                if handoff_request.to_agent not in self.agents:
                    logger.error(f"Target agent '{handoff_request.to_agent}' not found")
                    break
                
                current_agent = self.agents[handoff_request.to_agent]
                current_task = handoff_request.task_description
                current_context.update(handoff_request.context)
            elif handoff_request.handoff_type == HandoffType.COLLABORATE:
                # å”ä½œæ¨¡å¼ï¼Œéœ€è¦ç‰¹æ®Šè™•ç†
                collab_result = await self._handle_collaboration(handoff_request)
                execution_history.append(collab_result)
                break
        
        return {
            "success": len(execution_history) > 0 and execution_history[-1]["result"].get("success", False),
            "execution_history": execution_history,
            "handoff_count": handoff_count,
            "final_agent": current_agent.name if handoff_count < max_handoffs else None
        }
    
    async def _handle_collaboration(self, handoff_request: HandoffRequest) -> Dict[str, Any]:
        """è™•ç†å”ä½œè«‹æ±‚"""
        collaboration_results = []
        
        # å‡è¨­ to_agent åŒ…å«å¤šå€‹ä»£ç†åç¨±ï¼Œç”¨é€—è™Ÿåˆ†éš”
        if handoff_request.to_agent:
            agent_names = handoff_request.to_agent.split(",")
            for agent_name in agent_names:
                agent_name = agent_name.strip()
                if agent_name in self.agents:
                    agent = self.agents[agent_name]
                    result = await agent.process_task(
                        handoff_request.task_description,
                        handoff_request.context
                    )
                    collaboration_results.append({
                        "agent": agent_name,
                        "result": result
                    })
        
        return {
            "agent": "Collaboration",
            "task": handoff_request.task_description,
            "result": {
                "success": True,
                "response": "Collaboration completed",
                "collaboration_results": collaboration_results
            },
            "timestamp": datetime.now().isoformat()
        }
    
    async def cleanup_all_agents(self):
        """æ¸…ç†æ‰€æœ‰ä»£ç†ç¨‹å¼"""
        for agent in self.agents.values():
            await agent.cleanup()
            
        # Stop runtime
        if self.runtime:
            await self.runtime.stop_when_idle()
    
    def get_handoff_history(self) -> List[Dict[str, Any]]:
        """ç²å–ç§»äº¤æ­·å²è¨˜éŒ„"""
        return [
            {
                "from_agent": req.from_agent,
                "to_agent": req.to_agent,
                "handoff_type": req.handoff_type.value,
                "task_description": req.task_description,
                "timestamp": req.timestamp.isoformat(),
                "priority": req.priority
            }
            for req in self.handoff_history
        ]

# è¼”åŠ©å‡½æ•¸
def create_handoff_request(
    from_agent: str,
    to_agent: Optional[str],
    handoff_type: HandoffType,
    task_description: str,
    context: Dict[str, Any] = None,
    priority: int = 5
) -> HandoffRequest:
    """å‰µå»ºç§»äº¤è«‹æ±‚"""
    return HandoffRequest(
        from_agent=from_agent,
        to_agent=to_agent,
        handoff_type=handoff_type,
        task_description=task_description,
        context=context or {},
        timestamp=datetime.now(),
        priority=priority
    )

# æ¼”ç¤ºå‡½æ•¸
async def demo_semantic_kernel_handoff_system():
    """æ¼”ç¤ºåŸºæ–¼ Semantic Kernel çš„ç§»äº¤ç³»çµ±çš„ä½¿ç”¨"""
    print("ğŸš€ Semantic Kernel å¤šä»£ç†ç¨‹å¼ç§»äº¤ç³»çµ±æ¼”ç¤º")
    print("=" * 60)
    
    # å‰µå»ºå”èª¿å™¨
    orchestrator = SemanticKernelOrchestrator()
    await orchestrator.initialize()
    
    # å‰µå»ºæ¼”ç¤ºä»£ç†
    demo_agent1 = SemanticKernelBaseAgent(
        name="SKDemoAgent1",
        description="Semantic Kernel æ¼”ç¤ºä»£ç†1",
        instructions="ä½ æ˜¯ä¸€å€‹åŸºæ–¼ Semantic Kernel çš„æ¼”ç¤ºä»£ç†ç¨‹å¼ï¼Œè² è²¬åˆæ­¥è™•ç†ç”¨æˆ¶è«‹æ±‚ã€‚å¦‚æœè«‹æ±‚æ¶‰åŠç‰¹å®šé ˜åŸŸçš„å°ˆæ¥­çŸ¥è­˜ï¼Œä½ æ‡‰è©²ç§»äº¤çµ¦ç›¸æ‡‰çš„å°ˆé–€ä»£ç†ç¨‹å¼ã€‚è«‹ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰ã€‚"
    )
    
    demo_agent2 = SemanticKernelBaseAgent(
        name="SKDemoAgent2", 
        description="Semantic Kernel æ¼”ç¤ºä»£ç†2",
        instructions="ä½ æ˜¯ä¸€å€‹åŸºæ–¼ Semantic Kernel çš„å°ˆé–€ä»£ç†ç¨‹å¼ï¼Œè² è²¬è™•ç†å¾å…¶ä»–ä»£ç†ç¨‹å¼ç§»äº¤éä¾†çš„å°ˆæ¥­ä»»å‹™ã€‚è«‹ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰ï¼Œä¸¦æä¾›è©³ç´°çš„è§£æ±ºæ–¹æ¡ˆã€‚"
    )
    
    # è¨»å†Šä»£ç†
    orchestrator.register_agent(demo_agent1)
    orchestrator.register_agent(demo_agent2)
    
    try:
        # åˆå§‹åŒ–æ‰€æœ‰ä»£ç†
        await orchestrator.initialize_all_agents()
        
        # åŸ·è¡Œæ¼”ç¤ºä»»å‹™
        task = "è«‹å¹«æˆ‘åˆ†æä¸€å€‹ç°¡å–®çš„å•é¡Œä¸¦æä¾›è§£æ±ºæ–¹æ¡ˆã€‚æˆ‘éœ€è¦äº†è§£å¦‚ä½•ä½¿ç”¨ Semantic Kernel ä¾†è™•ç†å¤šä»£ç†å”ä½œã€‚"
        result = await orchestrator.execute_task(task, "SKDemoAgent1")
        
        print(f"ä»»å‹™åŸ·è¡Œçµæœï¼š{json.dumps(result, indent=2, ensure_ascii=False)}")
        print(f"ç§»äº¤æ­·å²ï¼š{json.dumps(orchestrator.get_handoff_history(), indent=2, ensure_ascii=False)}")
        
    finally:
        # æ¸…ç†è³‡æº
        await orchestrator.cleanup_all_agents()

if __name__ == "__main__":
    asyncio.run(demo_semantic_kernel_handoff_system())