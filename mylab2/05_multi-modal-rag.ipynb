{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catalog of Contents\n",
    "\n",
    "1. [Process documents and convert to Markdown](###1.-Convert-document-to-Markdown-with-images-and-tables)\n",
    "2. [Process images in documents and update MD](###2.-Extract-images-from-document-and-save-locally-as-figure_xx.png)\n",
    "3. [Inference](#3.-Inference)\n",
    "4. [Define the helper function to concatenate function info](#Define-the-helper-function-to-concatenate-function-info)\n",
    "5. [Combine all components into a single function](#Combine-all-components-into-a-single-function)\n",
    "6. [Final test](#Final-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU openai\n",
    "%pip install -qU pyyaml\n",
    "%pip install -qU pdf2docx\n",
    "%pip install -qU tenacity\n",
    "%pip install -qU matplotlib\n",
    "%pip install -qU python-dotenv\n",
    "%pip install -qU tiktoken==0.7.0\n",
    "%pip install -qU langchain==0.1.0\n",
    "%pip install -qU azure-core==1.29.5\n",
    "%pip install -qU azure-storage-blob==12.19.0\n",
    "%pip install -qU azure-search-documents==11.4.0\n",
    "%pip install -qU azure-ai-documentintelligence==1.0.0b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Phase 1: Knowledge Ingestion\n",
    " 1. Convert document to Markdown with images and tables\n",
    " 2. Extract images from document and save locally as figure_xx.png\n",
    " 3. Loop: Generate descriptions for images and insert into original Markdown\n",
    " 4. Upload local images to cloud storage\n",
    " 5. Generate chunks, ensuring content within HTML tags remains intact\n",
    "\n",
    "Phase 2: Knowledge Retrieval\n",
    " 1. Check retrieved chunk for \"blob://\" URLs\n",
    " 2. Parse \"blob://\" URL, extract storage information, and generate SAS URL\n",
    " 3. Replace \"blob://\" with SAS URL\n",
    " 4. Generate answer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.ai.documentintelligence\n",
    "\n",
    "print(azure.ai.documentintelligence.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../.env\")\n",
    "print(os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Convert document to Markdown with images and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import ContentFormat, AnalyzeResult\n",
    "# from azure.ai.documentintelligence.models import ContentFormat, AnalyzeOutputOption, AnalyzeResult\n",
    "\n",
    "\n",
    "doc_intelligence_endpoint = os.getenv(\n",
    "    \"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "doc_intelligence_key = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_KEY\")\n",
    "document_intelligence_client = DocumentIntelligenceClient(\n",
    "    endpoint=doc_intelligence_endpoint, credential=AzureKeyCredential(doc_intelligence_key))\n",
    "\n",
    "def analyze_document(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        poller = document_intelligence_client.begin_analyze_document(\n",
    "            \"prebuilt-layout\",\n",
    "            analyze_request=f,\n",
    "            content_type=\"application/octet-stream\",\n",
    "            polling_interval=3,\n",
    "            # output=[AnalyzeOutputOption.FIGURES],\n",
    "            output_content_format=ContentFormat.MARKDOWN\n",
    "        )\n",
    "\n",
    "    # result: AnalyzeResult = poller.result()\n",
    "    # operation_id = poller.details[\"operation_id\"]\n",
    "    # return operation_id, result\n",
    "\n",
    "    result: AnalyzeResult = poller.result()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "result = analyze_document(\"../00_data/US_11820651_B2.pdf\")\n",
    "# result = analyze_document(\"../00_data/刑法的私塾.pdf\")\n",
    "# operation_id, result = analyze_document(\n",
    "#     \"../00_data/Overview of LLMs_short.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "if result.figures and len(result.figures) > 0:\n",
    "    a = 1\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Markdown, display\n",
    "\n",
    "markdown_content = result.content\n",
    "\n",
    "# display(Markdown(markdown_content))\n",
    "display(Markdown(markdown_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_images import include_figures_in_md\n",
    "\n",
    "input_file_path = \"../00_data/US_11820651_B2.pdf\"\n",
    "containerName = \"rag-test\"\n",
    "folder = \"US_11820651_B2\"\n",
    "new_md_content = await include_figures_in_md(input_file_path, result, containerName,\n",
    "                                             folder, output_folder=\"data/cropped\")\n",
    "display(Markdown(new_md_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Process retrieved chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from azure.storage.blob.aio import BlobServiceClient\n",
    "from azure.storage.blob import BlobSasPermissions, generate_blob_sas\n",
    "\n",
    "sas_token_cache = {}\n",
    "\n",
    "\n",
    "def generate_sas_url(blob_client):\n",
    "    # Generate a unique key for the blob\n",
    "    blob_key = f\"{blob_client.account_name}/{blob_client.container_name}/{blob_client.blob_name}\"\n",
    "\n",
    "    # Check if the SAS token is already cached and still valid\n",
    "    if blob_key in sas_token_cache:\n",
    "        sas_token, expiry_time = sas_token_cache[blob_key]\n",
    "        if expiry_time > datetime.now(timezone.utc):\n",
    "            # Return the cached SAS URL if the token is still valid\n",
    "            return f\"https://{blob_client.account_name}.blob.core.windows.net/{blob_client.container_name}/{blob_client.blob_name}?{sas_token}\"\n",
    "\n",
    "    # Generate a new SAS token\n",
    "    expiry_time = datetime.now(timezone.utc) + timedelta(hours=1)\n",
    "    sas_token = generate_blob_sas(\n",
    "        blob_client.account_name,\n",
    "        blob_client.container_name,\n",
    "        blob_client.blob_name,\n",
    "        account_key=blob_client.credential.account_key,\n",
    "        permission=BlobSasPermissions(read=True),\n",
    "        expiry=expiry_time\n",
    "    )\n",
    "\n",
    "    # Cache the new SAS token and its expiry time\n",
    "    sas_token_cache[blob_key] = (sas_token, expiry_time)\n",
    "\n",
    "    # Generate the SAS URL\n",
    "    sas_url = f\"https://{blob_client.account_name}.blob.core.windows.net/{blob_client.container_name}/{blob_client.blob_name}?{sas_token}\"\n",
    "\n",
    "    return sas_url\n",
    "\n",
    "\n",
    "def extract_blob_url(input_str):\n",
    "    # Define the regex pattern to match the blob URL\n",
    "    pattern = r'blob://[^\\s\\)]+\\.png'\n",
    "\n",
    "    # Find all matches in the input string\n",
    "    matches = re.findall(pattern, input_str)\n",
    "\n",
    "    # Return the list of matched URLs\n",
    "    return matches\n",
    "\n",
    "\n",
    "def extract_elements_from_blob_url(blob_url):\n",
    "    # Split the URL by '/'\n",
    "    elements = blob_url.split('/')\n",
    "\n",
    "    # Extract the required elements\n",
    "    if len(elements) >= 6:\n",
    "        return elements[2], elements[3], elements[4], elements[5]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "async def process(md_content: str):\n",
    "    blob_urls = extract_blob_url(md_content)\n",
    "    sas_urls = {}\n",
    "\n",
    "    async with BlobServiceClient.from_connection_string(os.environ[\"AzureWebJobsStorage\"]) as storage_client:\n",
    "        for blob_url in blob_urls:\n",
    "            elements = extract_elements_from_blob_url(blob_url)\n",
    "            if elements:\n",
    "                _, container_name, blob_name = elements[0], elements[1], '/'.join(\n",
    "                    elements[2:])\n",
    "                blob_client = storage_client.get_blob_client(\n",
    "                    container=container_name, blob=blob_name)\n",
    "                sas_url = generate_sas_url(blob_client)\n",
    "                sas_urls[blob_url] = sas_url\n",
    "\n",
    "    # Replace blob URLs with SAS URLs in the markdown content\n",
    "    for blob_url, sas_url in sas_urls.items():\n",
    "        md_content = md_content.replace(blob_url, sas_url)\n",
    "\n",
    "    return md_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_md_content = \"\"\"# 1\\\\. Introduction  \\nLanguage plays a fundamental role in facilitating commu- nication and self-expression for humans, and their interaction with machines. The need for generalized models stems from the growing demand for machines to handle complex language tasks, including translation, summarization, information re- trieval, conversational interactions, etc. Recently, significant breakthroughs have been witnessed in language models, pri- marily attributed to transformers [1], increased computational capabilities, and the availability of large-scale training data. These developments have brought about a revolutionary trans- formation by enabling the creation of LLMs that can approxi- mate human-level performance on various tasks [2, 3]. Large  \\n<figure>\\n\\n![](https://xxxxxxx)<!-- FigureContent=\\\"The image is a bar chart titled \\\"Papers Released over Years,\\\" depicting the trend of academic papers with keywords related to \\\"Large Language Model\\\" (LLMs), \\\"LLMs + Fine-Tuning,\\\" and \\\"LLMs + Alignment\\\" from 2018 to 2023. The chart uses three colors: blue for \\\"LLMs,\\\" red for \\\"LLMs + Fine-Tuning,\\\" and green for \\\"LLMs + Alignment.\\\"\\n\\n- **2018**: 42 papers on LLMs, 3 on Fine-Tuning, and 12 on Alignment.\\n- **2019**: 60 papers on LLMs, 32 on Fine-Tuning, and 17 on Alignment.\\n- **2020**: 114 papers on LLMs, 66 on Fine-Tuning, and 26 on Alignment.\\n- **2021**: 260 papers on LLMs, 153 on Fine-Tuning, and 58 on Alignment.\\n- **2022**: 1,210 papers on LLMs, 582 on Fine-Tuning, and 238 on Alignment.\\n- **2023**: 20,900 papers on LLMs, 7,260 on Fine-Tuning, and 4,740 on Alignment.\\n\\nThe chart shows a significant increase in papers over the years, especially in 2023.\\\" --></figure>  \\n<!-- Footnote=\\\"\\\\*Equal contribution\\\" -->  \\n<!-- Footnote=\\\"Email addresses: humza\\\\_naveed@yahoo. com (Humza Naveed),\\\" -->  \\n<!-- Footnote=\\\"aukhanee@gmail. com (Asad Ullah Khan), shiqiu@cse.cuhk.edu.hk (Shi Qiu), muhammad. saqib@data61.csiro. au (Muhammad Saqib),\\\" -->  \\n<!-- Footnote=\\\"saeed. anwar@kfupm. edu. sa (Saeed Anwar), muhammad. usman@kfupm. edu. sa (Muhammad Usman), naveed. akhtar1@unimelb. edu. au (Naveed Akhtar), nick. barnes@anu. edu. au (Nick Barnes), ajmal.mian@uwa.edu.au (Ajmal Mian)\\\" -->  \\n<!-- PageFooter=\\\"Preprint submitted to Elsevier\\\" -->  \\n<!-- PageFooter=\\\"April 11, 2024\\\" -->\\n:selected: :selected: :unselected: :unselected: :unselected: :selected: :unselected: :unselected: :unselected: :unselected: :unselected: :selected: :unselected: :unselected: :selected: :unselected: :unselected: :selected: :unselected: :unselected: :selected: :selected: :unselected: :unselected:<figure>\\n\\n![](https://xxxxxx)<!-- FigureContent=\\\"The image is a timeline chart illustrating the release of various large language models (LLMs) from 2019 to 2024. It uses blue and orange cards to distinguish between 'pre-trained' and 'instruction-tuned' models, respectively. Models on the upper half of the timeline are open-source, while those on the lower half are closed-source.\\n\\nKey highlights include:\\n\\n- **2019-2020**: Introduction of models like T5 and mT5 (both pre-trained and open-source).\\n- **2021**: Notable releases such as GPT-3 (pre-trained, closed-source) and T0 (instruction-tuned, open-source).\\n- **2022**: Many models released, including Codex and WebGPT (pre-trained, closed-source) and OPT-IML (instruction-tuned, open-source).\\n- **2023**: Models like LLaMA and Code Llama (pre-trained, open-source) and ChatGPT (instruction-tuned, closed-source) are released.\\n- **2024**: Expected releases include PanGu-Σ, BloombergGPT, and Gemini (all pre-trained, closed-source).\\n\\nThe chart emphasizes the growing trend toward instruction-tuned and open-source models in natural language processing research.\\\" --></figure>  \\nLanguage Models (LLMs) have emerged as cutting-edge arti- ficial intelligence systems that can process and generate text with coherent communication [4], and generalize to multiple tasks [5, 6].\"\"\"\n",
    "blob_urls = extract_blob_url(new_md_content)\n",
    "processed_md_content = await process(new_md_content)\n",
    "processed_md_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_md_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(processed_md_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# Function to find complete tags and replace with placeholders\n",
    "def preserve_tags(text, tag):\n",
    "    pattern = fr\"(<{tag}.*?>.*?</{tag}>)\"\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    for i, match in enumerate(matches):\n",
    "        text = text.replace(match, f\"[[PLACEHOLDER_{i}]]\")\n",
    "    return text, matches\n",
    "\n",
    "# Function to restore tags from placeholders\n",
    "def restore_tags(text, matches):\n",
    "    for i, match in enumerate(matches):\n",
    "        text = text.replace(f\"[[PLACEHOLDER_{i}]]\", match)\n",
    "    return text\n",
    "\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "    (\"####\", \"Header 4\"),\n",
    "    (\"#####\", \"Header 5\"),\n",
    "    (\"######\", \"Header 6\"),  \n",
    "    (\"#######\", \"Header 7\"), \n",
    "    (\"########\", \"Header 8\")\n",
    "]\n",
    "\n",
    "md_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on, strip_headers=False)\n",
    "\n",
    "# Process the markdown content to preserve tags\n",
    "replaced_md_content, matches = preserve_tags(new_md_content, \"figure\")\n",
    "md_header_splits = md_splitter.split_text(replaced_md_content)\n",
    "\n",
    "chunk_size = 512\n",
    "chunk_overlap = 50\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=\"gpt-4\",\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "\n",
    "# Split the text into documents\n",
    "splits = text_splitter.split_documents(md_header_splits)\n",
    "\n",
    "# Restore tags in each split\n",
    "restored_splits = [Document(page_content=restore_tags(split.page_content, matches)) for split in splits]\n",
    "\n",
    "print(splits[3].page_content)\n",
    "print(\"------------------------------\")\n",
    "print(restored_splits[3].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "encoding = tiktoken.encoding_for_model('gpt-4o')\n",
    "encoding\n",
    "\n",
    "\n",
    "def gen_token_num_plot(splits):\n",
    "    import tiktoken\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    encoding = tiktoken.encoding_for_model('gpt-4')\n",
    "\n",
    "    def get_max_tokens(splits):\n",
    "        max_tokens = 0\n",
    "        for split in splits:\n",
    "            num_tokens = len(encoding.encode(split.page_content))\n",
    "            if num_tokens > max_tokens:\n",
    "                max_tokens = num_tokens\n",
    "        return max_tokens\n",
    "\n",
    "    # get_max_chars(splits)\n",
    "\n",
    "\n",
    "    # Calculate the range for each bar\n",
    "    max_token = get_max_tokens(splits)\n",
    "\n",
    "    # Calculate the count scope for each range\n",
    "    range_size = max_token / 5\n",
    "\n",
    "    # Initialize the count for each range\n",
    "    range_counts = [0] * 5\n",
    "\n",
    "    # Count the number of splits in each range\n",
    "    for split in splits:\n",
    "        num_token = len(encoding.encode(split.page_content))\n",
    "        range_index = min(int(num_token / range_size), 4)\n",
    "        range_counts[range_index] += 1\n",
    "\n",
    "    # Set the figure size\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "    # Plot the bar chart\n",
    "    ax.bar(range(1, 6), range_counts)\n",
    "    ax.set_xlabel('Count Scope')\n",
    "    ax.set_ylabel('Number of Splits')\n",
    "    ax.set_title('Number of Splits in Each Range')\n",
    "\n",
    "    # Set the x-axis tick labels to the count scope values\n",
    "    xtick_labels = [f'{int(i * range_size)}-{int((i+1) * range_size)}' for i in range(5)]\n",
    "    ax.set_xticks(range(1, 6))\n",
    "    ax.set_xticklabels(xtick_labels)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(restored_splits)} in total\")\n",
    "gen_token_num_plot(restored_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient, SearchIndexingBufferedSender\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.models import (\n",
    "    QueryAnswerType,\n",
    "    QueryCaptionType,\n",
    "    QueryType,\n",
    "    VectorizedQuery,\n",
    ")\n",
    "from azure.search.documents.indexes.models import (\n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SearchField,\n",
    "    SemanticSearch,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchProfile,\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    VectorSearch,\n",
    "    ExhaustiveKnnParameters,\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswParameters,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    VectorSearchProfile,\n",
    ")\n",
    "\n",
    "# Configure environment variables\n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "\n",
    "credential = AzureKeyCredential(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"index-multimodal\"\n",
    "\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=service_endpoint, credential=credential)\n",
    "\n",
    "try:\n",
    "    result = index_client.delete_index(index_name)\n",
    "    print ('Index', index_name, 'Deleted')\n",
    "except Exception as ex:\n",
    "    print (ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a search index\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True,\n",
    "                sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"category\", type=SearchFieldDataType.String,\n",
    "                    filterable=True),\n",
    "    SimpleField(name=\"source\", type=SearchFieldDataType.String,\n",
    "                filterable=True),\n",
    "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "]\n",
    "\n",
    "# Configure the vector search configuration\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\",\n",
    "            kind=VectorSearchAlgorithmKind.HNSW,\n",
    "            parameters=HnswParameters(\n",
    "                m=4,\n",
    "                ef_construction=400,\n",
    "                ef_search=500,\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE\n",
    "            )\n",
    "        ),\n",
    "        ExhaustiveKnnAlgorithmConfiguration(\n",
    "            name=\"myExhaustiveKnn\",\n",
    "            kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,\n",
    "            parameters=ExhaustiveKnnParameters(\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "        ),\n",
    "        VectorSearchProfile(\n",
    "            name=\"myExhaustiveKnnProfile\",\n",
    "            algorithm_configuration_name=\"myExhaustiveKnn\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        keywords_fields=[SemanticField(field_name=\"category\")],\n",
    "        content_fields=[SemanticField(field_name=\"content\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_search=semantic_search)\n",
    "\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings\n",
    "Read your data, generate OpenAI embeddings and export to a format to insert your Azure AI Search index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "embedding_client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def generate_embeddings(texts, model=model):\n",
    "    return embedding_client.embeddings.create(input=texts, model=model).data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_prefix = \"Overview of LLMs.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(restored_splits[3].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "batch_inputs = [restored_splits[i].page_content for i in range(len(restored_splits))]\n",
    "BATCH_SIZE = 1000  # you can submit up to 2048 embedding inputs per request\n",
    "\n",
    "embeddings = []\n",
    "for batch_start in range(0, len(batch_inputs), BATCH_SIZE):\n",
    "    batch_end = batch_start + BATCH_SIZE\n",
    "    batch = batch_inputs[batch_start: batch_end]\n",
    "    response = client.embeddings.create(input=batch, model=model)\n",
    "    for i, be in enumerate(response.data):\n",
    "        # double check embeddings are in same order as input\n",
    "        assert i == be.index\n",
    "    batch_embeddings = [e.embedding for e in response.data]\n",
    "    embeddings.extend(batch_embeddings)\n",
    "\n",
    "documents = []\n",
    "counter = 0\n",
    "for item in restored_splits:\n",
    "    file_name = file_prefix.split('.')[0]\n",
    "    documents.append({\n",
    "        'id': str(uuid.uuid4()),\n",
    "        'title':  item.metadata.get('Header 1', file_name),\n",
    "        'content': item.page_content,\n",
    "        'category': item.metadata.get('Header 2', file_name),\n",
    "        'source': file_prefix,\n",
    "        'contentVector': embeddings[counter]\n",
    "    })\n",
    "    counter += 1\n",
    "\n",
    "print(f'{len(documents)} documents generated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"AZURE_SEARCH_ENDPOINT2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "admin_key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "credential = AzureKeyCredential(admin_key)\n",
    "client = SearchClient(endpoint=endpoint,\n",
    "                      index_name=index_name,\n",
    "                      credential=credential,)\n",
    "client.upload_documents(documents)\n",
    "print(f\"Uploaded {len(documents)} documents in total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def generate_embeddings(query, model=model):\n",
    "    return embedding_client.embeddings.create(input=[query], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Hybrid Search\n",
    "query = \"How is the trend of LLM releases?\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    service_endpoint, index_name, AzureKeyCredential(key))\n",
    "vector_query = VectorizedQuery(vector=generate_embeddings(query),\n",
    "                               k_nearest_neighbors=5,\n",
    "                               fields=\"contentVector\")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"title\", \"content\", \"source\"],\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name='my-semantic-config',\n",
    "    query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=5\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "for answer in semantic_answers:\n",
    "    if answer.highlights:\n",
    "        print(f\"Semantic Answer: {answer.highlights}\")\n",
    "    else:\n",
    "        print(f\"Semantic Answer: {answer.text}\")\n",
    "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "output = []\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"result: {result}\")\n",
    "    # print(f\"source: {result['source']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "\n",
    "    output.append(result['content'])\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from azure.storage.blob.aio import BlobServiceClient\n",
    "from azure.storage.blob import BlobSasPermissions, generate_blob_sas\n",
    "\n",
    "sas_token_cache = {}\n",
    "\n",
    "\n",
    "def generate_sas_url(blob_client):\n",
    "    # Generate a unique key for the blob\n",
    "    blob_key = f\"{blob_client.account_name}/{blob_client.container_name}/{blob_client.blob_name}\"\n",
    "\n",
    "    # Check if the SAS token is already cached and still valid\n",
    "    if blob_key in sas_token_cache:\n",
    "        sas_token, expiry_time = sas_token_cache[blob_key]\n",
    "        if expiry_time > datetime.now(timezone.utc):\n",
    "            # Return the cached SAS URL if the token is still valid\n",
    "            return f\"https://{blob_client.account_name}.blob.core.windows.net/{blob_client.container_name}/{blob_client.blob_name}?{sas_token}\"\n",
    "\n",
    "    # Generate a new SAS token\n",
    "    expiry_time = datetime.now(timezone.utc) + timedelta(hours=1)\n",
    "    sas_token = generate_blob_sas(\n",
    "        blob_client.account_name,\n",
    "        blob_client.container_name,\n",
    "        blob_client.blob_name,\n",
    "        account_key=blob_client.credential.account_key,\n",
    "        permission=BlobSasPermissions(read=True),\n",
    "        expiry=expiry_time\n",
    "    )\n",
    "\n",
    "    # Cache the new SAS token and its expiry time\n",
    "    sas_token_cache[blob_key] = (sas_token, expiry_time)\n",
    "\n",
    "    # Generate the SAS URL\n",
    "    sas_url = f\"https://{blob_client.account_name}.blob.core.windows.net/{blob_client.container_name}/{blob_client.blob_name}?{sas_token}\"\n",
    "\n",
    "    return sas_url\n",
    "\n",
    "\n",
    "def extract_blob_url(input_str):\n",
    "    # Define the regex pattern to match the blob URL\n",
    "    pattern = r'blob://[^\\s\\)]+\\.png'\n",
    "\n",
    "    # Find all matches in the input string\n",
    "    matches = re.findall(pattern, input_str)\n",
    "\n",
    "    # Return the list of matched URLs\n",
    "    return matches\n",
    "\n",
    "\n",
    "def extract_elements_from_blob_url(blob_url):\n",
    "    # Split the URL by '/'\n",
    "    elements = blob_url.split('/')\n",
    "\n",
    "    # Extract the required elements\n",
    "    if len(elements) >= 6:\n",
    "        return elements[2], elements[3], elements[4], elements[5]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "async def process(md_content: str):\n",
    "    blob_urls = extract_blob_url(md_content)\n",
    "    sas_urls = {}\n",
    "\n",
    "    async with BlobServiceClient.from_connection_string(os.environ[\"AzureWebJobsStorage\"]) as storage_client:\n",
    "        for blob_url in blob_urls:\n",
    "            elements = extract_elements_from_blob_url(blob_url)\n",
    "            if elements:\n",
    "                _, container_name, blob_name = elements[0], elements[1], '/'.join(\n",
    "                    elements[2:])\n",
    "                blob_client = storage_client.get_blob_client(\n",
    "                    container=container_name, blob=blob_name)\n",
    "                sas_url = generate_sas_url(blob_client)\n",
    "                sas_urls[blob_url] = sas_url\n",
    "\n",
    "    # Replace blob URLs with SAS URLs in the markdown content\n",
    "    for blob_url, sas_url in sas_urls.items():\n",
    "        md_content = md_content.replace(blob_url, sas_url)\n",
    "\n",
    "    return md_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from IPython.display import Markdown\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from azure.search.documents.models import (\n",
    "    QueryAnswerType,\n",
    "    QueryCaptionType,\n",
    "    QueryType,\n",
    "    VectorizedQuery,\n",
    ")\n",
    "\n",
    "load_dotenv(\"../../.env\")\n",
    "\n",
    "# Configure environment variables\n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY2\")\n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT2\")\n",
    "credential = AzureKeyCredential(key)\n",
    "\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY_GPT_4o\")\n",
    "api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT_GPT_4o\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_MODEl_GPT_4o\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION_GPT_4o\")\n",
    "\n",
    "gpt_client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=api_base,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "\n",
    "embedding_client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    "\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def generate_embeddings(query, model=model):\n",
    "    return embedding_client.embeddings.create(input=[query], model=model).data[0].embedding\n",
    "\n",
    "\n",
    "async def infer(query: str, index_name: str):\n",
    "    search_client = SearchClient(\n",
    "        service_endpoint, index_name, AzureKeyCredential(key))\n",
    "    vector_query = VectorizedQuery(vector=generate_embeddings(query),\n",
    "                                   k_nearest_neighbors=5,\n",
    "                                   fields=\"contentVector\")\n",
    "\n",
    "    results = search_client.search(\n",
    "        search_text=query,\n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"title\", \"content\", \"source\"],\n",
    "        query_type=QueryType.SEMANTIC,\n",
    "        semantic_configuration_name='my-semantic-config',\n",
    "        query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "        query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "        top=5\n",
    "    )\n",
    "\n",
    "    output = []\n",
    "    for result in results:\n",
    "        processed_chunk = await process(result['content'])\n",
    "        output.append(processed_chunk)\n",
    "\n",
    "    context = '\\n'.join(output)\n",
    "\n",
    "    prompt = \"\"\"\n",
    "        {{question}}\n",
    "\n",
    "        Sources:\n",
    "        {{context}}\n",
    "    \"\"\"\n",
    "\n",
    "    final_prompt = prompt.replace(\n",
    "        \"{{question}}\", query).replace(\"{{context}}\", context)\n",
    "    \n",
    "    # print(final_prompt)\n",
    "\n",
    "    response = gpt_client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[{'role': 'system', 'content': \"You are a helpful assistant. Try to answer user's question by referencing the following related background information.\\n  If there is not enough information to answer user's question, just say not enough information.\\n  If there are relevant images, please embed the image in the response. DON'T modify the image URL.\"},\n",
    "                  {\"role\": \"user\", \"content\": final_prompt}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How is the trend of LLM releases?\"\n",
    "index_name = \"index-multimodal\"\n",
    "response = await infer(query, index_name)\n",
    "Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is PEFT? How it works?\"\n",
    "index_name = \"index-multimodal\"\n",
    "response = await infer(query, index_name)\n",
    "Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Show me the diagram of Parameter Efficient Fine-Tuning.\"\n",
    "index_name = \"index-multimodal\"\n",
    "response = await infer(query, index_name)\n",
    "Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How parameter-efficient fine-tuning works in detail?\"\n",
    "index_name = \"index-multimodal\"\n",
    "response = await infer(query, index_name)\n",
    "Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do tool augmented LLMs work?\"\n",
    "index_name = \"index-multimodal\"\n",
    "response = await infer(query, index_name)\n",
    "Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How does the BLOOM architecture look like?\"\n",
    "index_name = \"index-multimodal\"\n",
    "response = await infer(query, index_name)\n",
    "Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Show me an example of attention patterns\"\n",
    "index_name = \"index-multimodal\"\n",
    "response = await infer(query, index_name)\n",
    "Markdown(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
